# import streamlit as st
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# import pandas as pd
# from PIL import Image
# import tensorflow as tf
# from tensorflow.keras.applications.efficientnet import preprocess_input as efficient_preprocess
# from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
# from tensorflow.keras.utils import register_keras_serializable
# import cv2
# import time
# import warnings
# warnings.filterwarnings('ignore')

# # ===========================
# # Initialize Session State
# # ===========================
# if 'captured_image' not in st.session_state:
#     st.session_state.captured_image = None
# if 'camera_active' not in st.session_state:
#     st.session_state.camera_active = False
# if 'show_preview' not in st.session_state:
#     st.session_state.show_preview = False
# if 'prediction_made' not in st.session_state:
#     st.session_state.prediction_made = False
# if 'prediction_results' not in st.session_state:
#     st.session_state.prediction_results = None

# # ===========================
# # Page Configuration
# # ===========================
# st.set_page_config(
#     page_title="ASL Recognition System",
#     page_icon="âœ‹",
#     layout="wide"
# )

# # ===========================
# # Custom CSS
# # ===========================
# st.markdown("""
# <style>
#     .main-header {
#         font-size: 2.5rem;
#         color: #1E88E5;
#         text-align: center;
#         margin-bottom: 2rem;
#     }
#     .sub-header {
#         font-size: 1.5rem;
#         color: #43A047;
#         margin-top: 1.5rem;
#     }
#     .prediction-box {
#         background-color: #E3F2FD;
#         padding: 1.5rem;
#         border-radius: 15px;
#         border-left: 5px solid #1E88E5;
#         margin: 1rem 0;
#         box-shadow: 0 4px 6px rgba(0,0,0,0.1);
#     }
#     .camera-preview {
#         border: 3px solid #4CAF50;
#         border-radius: 10px;
#         padding: 10px;
#         background-color: #000;
#         margin: 10px 0;
#     }
#     .captured-image-box {
#         border: 3px solid #FF9800;
#         border-radius: 10px;
#         padding: 10px;
#         background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
#     }
#     .webcam-button {
#         background: linear-gradient(45deg, #4CAF50, #2E7D32) !important;
#         color: white !important;
#         border: none !important;
#         padding: 12px 24px !important;
#         border-radius: 8px !important;
#         font-size: 16px !important;
#         font-weight: bold !important;
#         cursor: pointer !important;
#         margin: 5px 0 !important;
#     }
#     .capture-button {
#         background: linear-gradient(45deg, #FF5722, #D84315) !important;
#     }
#     .stButton > button {
#         width: 100%;
#     }
# </style>
# """, unsafe_allow_html=True)

# # ===========================
# # Register custom preprocessing function
# # ===========================
# @register_keras_serializable()
# def custom_preprocess_input(x):
#     return efficient_preprocess(x)

# # ===========================
# # Load Models
# # ===========================
# @st.cache_resource
# def load_models():
#     try:
#         models = {}
        
#         # Load CNN Model
#         try:
#             models["CNN (128x128)"] = tf.keras.models.load_model("Models/CNN_model_V1.keras")
#             st.sidebar.success("âœ“ CNN Model Loaded")
#         except Exception as e:
#             st.sidebar.error(f"âœ— CNN Model: {str(e)[:50]}...")
        
#         # Load EfficientNetB0 Model
#         try:
#             models["EfficientNetB0 (128x128)"] = tf.keras.models.load_model("Models/EfficientNetB0_model.h5")
#             st.sidebar.success("âœ“ EfficientNetB0 Model Loaded")
#         except Exception as e:
#             st.sidebar.error(f"âœ— EfficientNetB0: {str(e)[:50]}...")
        
#         # Load EfficientNetB0_V2 Model
#         try:
#             models["EfficientNetB0_V2 (128x128)"] = tf.keras.models.load_model(
#                 "Models/EfficientV2.keras",
#                 custom_objects={"preprocess_input": custom_preprocess_input}
#             )
#             st.sidebar.success("âœ“ EfficientNetB0_V2 Model Loaded")
#         except Exception as e:
#             st.sidebar.error(f"âœ— EfficientNetB0_V2: {str(e)[:50]}...")
        
#         # Load ResNet50 Model
#         try:
#             models["ResNet50 (224x224)"] = tf.keras.models.load_model("Models/ResNet50_model_updated.keras")
#             st.sidebar.success("âœ“ ResNet50 Model Loaded")
#         except Exception as e:
#             st.sidebar.error(f"âœ— ResNet50: {str(e)[:50]}...")
        
#         return models
#     except Exception as e:
#         st.error(f"Error loading models: {str(e)}")
#         return {}

# models = load_models()

# # ===========================
# # Class Names
# # ===========================
# class_names = [
#     'A','B','C','D','E','F','G','H','I','J','K','L','M',
#     'N','O','P','Q','R','S','T','U','V','W','X','Y','Z',
#     'del', 'nothing', 'space'  
# ]

# # ===========================
# # Webcam Functions with LIVE PREVIEW
# # ===========================
# def capture_with_preview():
#     """Capture photo from webcam with live preview in Streamlit"""
#     cap = cv2.VideoCapture(0)
    
#     if not cap.isOpened():
#         st.error("âŒ Cannot access webcam. Please check camera permissions.")
#         return None
    
#     # Set camera properties
#     cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
#     cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
#     st.session_state.camera_active = True
#     st.session_state.show_preview = True
    
#     # Create placeholders
#     preview_placeholder = st.empty()
#     status_placeholder = st.empty()
#     button_placeholder = st.empty()
    
#     captured_image = None
    
#     # Buttons
#     col1, col2 = button_placeholder.columns(2)
    
#     with col1:
#         capture_btn = st.button("ğŸ“¸ CAPTURE NOW", key="live_capture", type="primary", use_container_width=True)
    
#     with col2:
#         cancel_btn = st.button("âŒ CANCEL", key="cancel_capture", use_container_width=True)
    
#     # Capture loop
#     while st.session_state.camera_active:
#         ret, frame = cap.read()
#         if not ret:
#             break
        
#         # Create display frame with annotations
#         display_frame = frame.copy()
#         height, width = display_frame.shape[:2]
        
#         # Draw green box for hand placement
#         box_size = 300
#         x1 = width // 2 - box_size // 2
#         y1 = height // 2 - box_size // 2
#         x2 = x1 + box_size
#         y2 = y1 + box_size
        
#         cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
        
#         # Add instruction text
#         cv2.putText(display_frame, "Place hand in green box", (10, 30), 
#                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
#         cv2.putText(display_frame, "Press 'CAPTURE NOW' button", (10, 70), 
#                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
#         # Convert BGR to RGB for Streamlit
#         display_frame_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
        
#         # Show live preview
#         preview_placeholder.image(display_frame_rgb, channels="RGB", 
#                                  caption="Live Camera Preview - Place hand in green box",
#                                  use_container_width=True)
        
#         # Show status
#         status_placeholder.info("ğŸŸ¢ Camera is active - Adjust your hand position")
        
#         # Check for button presses
#         if capture_btn:
#             # Crop to green box area
#             if y1 >= 0 and x1 >= 0 and y2 <= height and x2 <= width:
#                 captured_frame = frame[y1:y2, x1:x2]
#             else:
#                 captured_frame = frame
            
#             # Convert to RGB
#             captured_image = cv2.cvtColor(captured_frame, cv2.COLOR_BGR2RGB)
            
#             # Save to session state
#             st.session_state.captured_image = Image.fromarray(captured_image)
#             st.session_state.camera_active = False
            
#             # Show success message
#             status_placeholder.success("âœ… Photo captured successfully!")
            
#             # Show captured image
#             st.image(captured_image, caption="Captured Hand Sign", use_container_width=True)
#             break
        
#         elif cancel_btn:
#             status_placeholder.warning("âŒ Camera closed")
#             st.session_state.camera_active = False
#             break
        
#         # Small delay to prevent high CPU usage
#         time.sleep(0.03)
    
#     # Cleanup
#     cap.release()
#     cv2.destroyAllWindows()
#     st.session_state.camera_active = False
#     st.session_state.show_preview = False
    
#     return captured_image

# # ===========================
# # Normalization functions
# # ===========================
# def normalize_predictions(predictions):
#     """Normalize predictions to get proper confidence scores"""
#     predictions = np.array(predictions)
    
#     if predictions.ndim == 2:
#         exp_preds = np.exp(predictions - np.max(predictions, axis=1, keepdims=True))
#         predictions = exp_preds / np.sum(exp_preds, axis=1, keepdims=True)
    
#     predictions = np.clip(predictions, 0, 1)
#     return predictions

# # ===========================
# # Preprocessing Function
# # ===========================
# def prepare_image(image, model_name):
#     """Prepare image for model prediction"""
#     if isinstance(image, np.ndarray):
#         image = Image.fromarray(image)
    
#     if model_name == "CNN (128x128)":
#         target_size = (128, 128)
#         img = image.resize(target_size)
#         img_array = np.array(img).astype(np.float32) 
#         return img_array.reshape(1, 128, 128, 3), img_array
    
#     elif model_name == "EfficientNetB0 (128x128)":
#         target_size = (128, 128)
#         img = image.resize(target_size)
#         img_array = np.array(img).astype(np.float32)
#         img_array = efficient_preprocess(img_array)
#         return img_array.reshape(1, 128, 128, 3), np.array(img)
    
#     elif model_name == "EfficientNetB0_V2 (128x128)":
#         target_size = (128, 128)
#         img = image.resize(target_size)
#         img_array = np.array(img).astype(np.float32)
#         img_array = efficient_preprocess(img_array)
#         return img_array.reshape(1, 128, 128, 3), np.array(img)
    
#     elif model_name == "ResNet50 (224x224)":
#         target_size = (224, 224)
#         img = image.resize(target_size)
#         img_array = np.array(img).astype(np.float32)
#         img_array = resnet_preprocess(img_array)
#         return img_array.reshape(1, 224, 224, 3), np.array(img)
    
#     else:
#         target_size = (128, 128)
#         img = image.resize(target_size)
#         img_array = np.array(img).astype(np.float32) / 255.0
#         return img_array.reshape(1, 128, 128, 3), img_array

# # ===========================
# # Streamlit UI - Main Page
# # ===========================
# st.markdown('<h1 class="main-header">âœ‹ ASL Alphabet Recognition System</h1>', unsafe_allow_html=True)

# # Sidebar navigation
# st.sidebar.markdown("## Navigation")
# page = st.sidebar.radio(
#     "Go to:",
#     ["ğŸ  Single Model", "ğŸ“Š Model Comparison", "ğŸ“ˆ Model Performance"]
# )

# # Input method in sidebar
# st.sidebar.markdown("---")
# st.sidebar.markdown("## ğŸ“· Input Options")
# input_method = st.sidebar.radio(
#     "Choose input method:",
#     ["ğŸ“ Upload Image", "ğŸ“¸ Live Webcam"]
# )

# # Clear button
# if st.sidebar.button("ğŸ—‘ï¸ Clear All", type="secondary"):
#     st.session_state.captured_image = None
#     st.session_state.camera_active = False
#     st.session_state.prediction_made = False
#     st.session_state.prediction_results = None
#     st.rerun()

# # Model info in sidebar
# st.sidebar.markdown("---")
# st.sidebar.markdown("## ğŸ¤– Available Models")
# for model_name in models.keys():
#     st.sidebar.markdown(f"- {model_name}")

# # ===========================
# # Page 1: Single Model Prediction
# # ===========================
# if page == "ğŸ  Single Model":
#     st.markdown('<h2 class="sub-header">Single Model Prediction</h2>', unsafe_allow_html=True)
    
#     col1, col2 = st.columns([1, 1])
    
#     with col1:
#         st.markdown("### ğŸ“¸ Input Image")
        
#         image = None
        
#         if input_method == "ğŸ“ Upload Image":
#             uploaded_file = st.file_uploader(
#                 "Choose an ASL hand sign image",
#                 type=["jpg", "jpeg", "png"],
#                 help="Upload an image of ASL alphabet sign",
#                 key="file_uploader"
#             )
            
#             if uploaded_file is not None:
#                 try:
#                     image = Image.open(uploaded_file).convert("RGB")
#                     st.image(image, caption="Uploaded Image", use_container_width=True)
#                 except Exception as e:
#                     st.error(f"Error loading image: {str(e)}")
        
#         elif input_method == "ğŸ“¸ Live Webcam":
#             st.markdown("### Live Webcam Capture")
            
#             if not st.session_state.camera_active and not st.session_state.captured_image:
#                 st.info("ğŸ‘† Click 'Start Live Preview' to see camera feed")
                
#                 if st.button("ğŸ¥ Start Live Preview", type="primary", use_container_width=True):
#                     # This will trigger the camera preview
#                     st.session_state.camera_active = True
#                     st.rerun()
            
#             elif st.session_state.camera_active:
#                 # Show live preview section
#                 st.markdown('<div class="camera-preview">', unsafe_allow_html=True)
#                 st.markdown("#### ğŸ”´ LIVE PREVIEW")
#                 capture_with_preview()
#                 st.markdown('</div>', unsafe_allow_html=True)
            
#             # Show captured image if available
#             if st.session_state.captured_image is not None:
#                 st.markdown('<div class="captured-image-box">', unsafe_allow_html=True)
#                 st.markdown("#### âœ… CAPTURED IMAGE")
#                 st.image(st.session_state.captured_image, 
#                         caption="Your Hand Sign (Cropped from green box)", 
#                         use_container_width=True)
                
#                 # Image actions
#                 col_act1, col_act2, col_act3 = st.columns(3)
#                 with col_act1:
#                     if st.button("âœ… Use This", type="primary", use_container_width=True):
#                         image = st.session_state.captured_image
#                         st.success("âœ… Image selected for prediction")
                
#                 with col_act2:
#                     if st.button("ğŸ”„ Retake", use_container_width=True):
#                         st.session_state.captured_image = None
#                         st.session_state.camera_active = True
#                         st.rerun()
                
#                 with col_act3:
#                     if st.button("ğŸ—‘ï¸ Discard", use_container_width=True):
#                         st.session_state.captured_image = None
#                         st.rerun()
                
#                 st.markdown('</div>', unsafe_allow_html=True)
#                 image = st.session_state.captured_image
        
#         # Display ASL reference if no image
#         if image is None:
#             with st.expander("ğŸ“š Quick ASL Reference"):
#                 st.markdown("""
#                 **Common Letters:**
#                 - **A**: âœŠ Fist with thumb alongside
#                 - **B**: âœ‹ Flat palm, fingers together  
#                 - **C**: C Curved fingers
#                 - **D**: ğŸ‘† Index finger up
#                 - **L**: ğŸ‘Œ OK sign
#                 - **Y**: ğŸ¤˜ Rock on sign
#                 """)
    
#     with col2:
#         st.markdown("### ğŸ¤– Model Selection & Prediction")
        
#         if not models:
#             st.error("âŒ No models loaded. Please check model files.")
#         else:
#             model_choice = st.selectbox(
#                 "Select a model:",
#                 list(models.keys()),
#                 key="model_select"
#             )
            
#             # Determine which image to use
#             current_image = None
#             if input_method == "ğŸ“ Upload Image" and image is not None:
#                 current_image = image
#             elif input_method == "ğŸ“¸ Live Webcam" and st.session_state.captured_image is not None:
#                 current_image = st.session_state.captured_image
            
#             if current_image is not None:
#                 st.markdown("---")
#                 st.markdown("### ğŸš€ Ready to Predict!")
                
#                 # Show image preview
#                 st.image(current_image, width=250, caption="Image for Prediction")
                
#                 # Big prediction button
#                 if st.button("ğŸ¯ PREDICT NOW", type="primary", use_container_width=True):
#                     with st.spinner("ğŸ” Analyzing hand sign..."):
#                         try:
#                             # Prepare image
#                             img_ready, img_display = prepare_image(current_image, model_choice)
                            
#                             # Get model and predict
#                             model = models[model_choice]
#                             prediction = model.predict(img_ready, verbose=0)
#                             prediction_norm = normalize_predictions(prediction)
                            
#                             # Get top 3 predictions
#                             top_3_idx = np.argsort(prediction_norm[0])[-3:][::-1]
#                             top_3_classes = [class_names[i] for i in top_3_idx]
#                             top_3_confidences = [float(prediction_norm[0][i]) * 100 for i in top_3_idx]
                            
#                             # Store results
#                             st.session_state.prediction_results = {
#                                 'top_3_classes': top_3_classes,
#                                 'top_3_confidences': top_3_confidences,
#                                 'model_name': model_choice,
#                                 'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
#                             }
#                             st.session_state.prediction_made = True
                            
#                             # Display results
#                             st.markdown('<div class="prediction-box">', unsafe_allow_html=True)
#                             st.markdown("## ğŸ“Š Prediction Results")
#                             st.markdown(f"### ğŸ¯ **{top_3_classes[0]}**")
                            
#                             confidence = top_3_confidences[0]
#                             if confidence > 85:
#                                 emoji = "ğŸŸ¢"
#                                 color = "#4CAF50"
#                             elif confidence > 70:
#                                 emoji = "ğŸŸ¡"
#                                 color = "#FF9800"
#                             else:
#                                 emoji = "ğŸ”´"
#                                 color = "#F44336"
                            
#                             st.markdown(f"**Confidence:** {emoji} <span style='color:{color}; font-size:24px; font-weight:bold;'>{confidence:.2f}%</span>", 
#                                        unsafe_allow_html=True)
                            
#                             st.progress(min(int(confidence), 100), text=f"{confidence:.2f}% confidence")
                            
#                             st.markdown("#### Other Predictions:")
#                             for i in range(1, 3):
#                                 col_a, col_b = st.columns([1, 3])
#                                 with col_a:
#                                     st.markdown(f"**{i+1}. {top_3_classes[i]}**")
#                                 with col_b:
#                                     conf = min(max(top_3_confidences[i], 0), 100)
#                                     st.progress(int(conf), text=f"{top_3_confidences[i]:.2f}%")
                            
#                             st.markdown('</div>', unsafe_allow_html=True)
                            
#                             # Visualization
#                             st.markdown("### ğŸ“ˆ Top 10 Predictions")
                            
#                             top_10_idx = np.argsort(prediction_norm[0])[::-1][:10]
#                             top_10_classes = [class_names[i] for i in top_10_idx]
#                             top_10_confidences = [float(prediction_norm[0][i]) * 100 for i in top_10_idx]
                            
#                             fig, ax = plt.subplots(figsize=(10, 6))
#                             colors = plt.cm.YlOrRd(np.linspace(0.4, 0.9, len(top_10_classes)))
#                             bars = ax.barh(top_10_classes[::-1], top_10_confidences[::-1], color=colors)
                            
#                             ax.set_xlabel('Confidence (%)')
#                             ax.set_title(f'Top 10 Predictions - {model_choice}')
#                             ax.set_xlim(0, 100)
                            
#                             for bar, conf in zip(bars, top_10_confidences[::-1]):
#                                 width = bar.get_width()
#                                 ax.text(width + 1, bar.get_y() + bar.get_height()/2, 
#                                        f'{conf:.1f}%', va='center', fontweight='bold')
                            
#                             st.pyplot(fig)
                            
#                             # Prediction details
#                             with st.expander("ğŸ” View Detailed Analysis"):
#                                 st.write(f"**Model:** {model_choice}")
#                                 st.write(f"**Time:** {time.strftime('%H:%M:%S')}")
                                
#                                 # Show all predictions
#                                 st.markdown("**All Predictions (Top 15):**")
#                                 all_preds = []
#                                 for i in range(len(class_names)):
#                                     all_preds.append({
#                                         "Class": class_names[i],
#                                         "Confidence": f"{prediction_norm[0][i] * 100:.2f}%"
#                                     })
                                
#                                 all_preds.sort(key=lambda x: float(x['Confidence'].strip('%')), reverse=True)
                                
#                                 for i, pred in enumerate(all_preds[:15]):
#                                     if i < 3:
#                                         medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i]
#                                         st.write(f"{medal} **{pred['Class']}**: {pred['Confidence']}")
#                                     else:
#                                         st.write(f"{i+1}. {pred['Class']}: {pred['Confidence']}")
                        
#                         except Exception as e:
#                             st.error(f"âŒ Prediction error: {str(e)}")
            
#             elif st.session_state.prediction_made and st.session_state.prediction_results:
#                 # Show previous prediction
#                 results = st.session_state.prediction_results
                
#                 st.markdown("## ğŸ“‹ Previous Prediction")
#                 st.markdown(f"### Result: **{results['top_3_classes'][0]}**")
#                 st.markdown(f"#### Confidence: **{results['top_3_confidences'][0]:.2f}%**")
#                 st.markdown(f"*Model: {results['model_name']} | Time: {results['timestamp']}*")
                
#                 if st.button("ğŸ”„ Make New Prediction", type="secondary"):
#                     st.session_state.prediction_made = False
#                     st.session_state.prediction_results = None
#                     st.rerun()
            
#             else:
#                 st.info("ğŸ‘† Capture or upload an image first, then click 'PREDICT NOW'")

# # ===========================
# # Page 2: Model Comparison
# # ===========================
# elif page == "ğŸ“Š Model Comparison":
#     st.markdown('<h2 class="sub-header">Model Comparison</h2>', unsafe_allow_html=True)
    
#     st.info("ğŸ” Compare predictions across all models")
    
#     # Input section
#     comparison_image = None
    
#     if input_method == "ğŸ“ Upload Image":
#         uploaded_file = st.file_uploader(
#             "Upload image for comparison",
#             type=["jpg", "jpeg", "png"],
#             key="compare_upload"
#         )
#         if uploaded_file is not None:
#             comparison_image = Image.open(uploaded_file).convert("RGB")
    
#     elif input_method == "ğŸ“¸ Live Webcam":
#         if st.session_state.captured_image is not None:
#             comparison_image = st.session_state.captured_image
#             st.image(comparison_image, caption="Captured Image", use_container_width=True)
#         else:
#             st.info("No captured image. Go to 'Single Model' page to capture first.")
    
#     if comparison_image is not None and st.button("ğŸ”„ Compare All Models", type="primary", use_container_width=True):
#         results = []
        
#         progress_bar = st.progress(0)
#         status_text = st.empty()
        
#         for idx, (model_name, model) in enumerate(models.items()):
#             status_text.text(f"Processing {model_name}...")
#             progress_bar.progress((idx + 1) / len(models))
            
#             try:
#                 img_ready, _ = prepare_image(comparison_image, model_name)
#                 prediction = model.predict(img_ready, verbose=0)
#                 prediction_norm = normalize_predictions(prediction)
                
#                 pred_idx = np.argmax(prediction_norm[0])
#                 pred_class = class_names[pred_idx]
#                 confidence = float(prediction_norm[0][pred_idx]) * 100
                
#                 results.append({
#                     "Model": model_name,
#                     "Prediction": pred_class,
#                     "Confidence": f"{confidence:.2f}%",
#                     "Raw Confidence": confidence
#                 })
                
#             except Exception as e:
#                 st.error(f"Error with {model_name}: {str(e)}")
        
#         status_text.text("âœ… Comparison complete!")
#         progress_bar.empty()
        
#         # Display results
#         st.markdown("### ğŸ“‹ Comparison Results")
        
#         results.sort(key=lambda x: x["Raw Confidence"], reverse=True)
        
#         for i, result in enumerate(results):
#             with st.container():
#                 cols = st.columns([1, 3, 2, 2])
                
#                 with cols[0]:
#                     rank_emoji = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"][i] if i < 5 else f"{i+1}."
#                     st.markdown(f"**{rank_emoji}**")
                
#                 with cols[1]:
#                     st.markdown(f"**{result['Model']}**")
                
#                 with cols[2]:
#                     st.markdown(f"**{result['Prediction']}**")
                
#                 with cols[3]:
#                     conf_color = "#4CAF50" if result["Raw Confidence"] > 80 else "#FF9800" if result["Raw Confidence"] > 60 else "#F44336"
#                     st.markdown(f"<span style='color:{conf_color}; font-weight:bold;'>{result['Confidence']}</span>", 
#                                unsafe_allow_html=True)
                
#                 st.progress(min(int(result["Raw Confidence"]), 100))

# # ===========================
# # Page 3: Model Performance
# # ===========================
# elif page == "ğŸ“ˆ Model Performance":
#     st.markdown('<h2 class="sub-header">Model Performance Metrics</h2>', unsafe_allow_html=True)
    
#     col_select, col_info = st.columns([2, 1])
    
#     with col_select:
#         selected_model = st.selectbox(
#             "Select model to view performance:",
#             list(models.keys()),
#             key="perf_select"
#         )
    
#     with col_info:
#         if selected_model:
#             # Mock accuracy
#             accuracy = 0.85
#             st.metric("Model Accuracy", f"{accuracy*100:.1f}%")
    
#     if selected_model:
#         # Display metrics
#         col1, col2, col3 = st.columns(3)
        
#         with col1:
#             st.metric("Classes", "29")
        
#         with col2:
#             input_size = "128Ã—128" if "128" in selected_model else "224Ã—224"
#             st.metric("Input Size", input_size)
        
#         with col3:
#             st.metric("Model Type", selected_model.split()[0])

# # ===========================
# # Footer
# # ===========================
# st.markdown("---")
# st.markdown("""
# <div style="text-align: center; color: #666; padding: 20px;">
#     <h4>âœ‹ ASL Alphabet Recognition System</h4>
#     <p><strong>Live Webcam Preview â€¢ Instant Prediction â€¢ Multi-Model Comparison</strong></p>
#     <p>See camera feed directly in browser â€¢ Green box for hand placement</p>
# </div>
# """, unsafe_allow_html=True)


import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from PIL import Image
import tensorflow as tf
from tensorflow.keras.applications.efficientnet import preprocess_input as efficient_preprocess
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.utils import register_keras_serializable
import cv2
import time
import warnings
warnings.filterwarnings('ignore')

# ===========================
# Initialize Session State
# ===========================
if 'captured_image' not in st.session_state:
    st.session_state.captured_image = None
if 'camera_active' not in st.session_state:
    st.session_state.camera_active = False
if 'show_preview' not in st.session_state:
    st.session_state.show_preview = False
if 'prediction_made' not in st.session_state:
    st.session_state.prediction_made = False
if 'prediction_results' not in st.session_state:
    st.session_state.prediction_results = None

# ===========================
# Page Configuration
# ===========================
st.set_page_config(
    page_title="ASL Recognition System",
    page_icon="âœ‹",
    layout="wide"
)

# ===========================
# Custom CSS
# ===========================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #43A047;
        margin-top: 1.5rem;
    }
    .prediction-box {
        background-color: #E3F2FD;
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #1E88E5;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .camera-preview {
        border: 3px solid #4CAF50;
        border-radius: 10px;
        padding: 10px;
        background-color: #000;
        margin: 10px 0;
    }
    .captured-image-box {
        border: 3px solid #FF9800;
        border-radius: 10px;
        padding: 10px;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    .webcam-button {
        background: linear-gradient(45deg, #4CAF50, #2E7D32) !important;
        color: white !important;
        border: none !important;
        padding: 12px 24px !important;
        border-radius: 8px !important;
        font-size: 16px !important;
        font-weight: bold !important;
        cursor: pointer !important;
        margin: 5px 0 !important;
    }
    .capture-button {
        background: linear-gradient(45deg, #FF5722, #D84315) !important;
    }
    .stButton > button {
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

# ===========================
# Register custom preprocessing function
# ===========================
@register_keras_serializable()
def custom_preprocess_input(x):
    return efficient_preprocess(x)

# ===========================
# Load Models
# ===========================
@st.cache_resource
def load_models():
    try:
        models = {}
        
        # Load CNN Model
        try:
            models["CNN (128x128)"] = tf.keras.models.load_model("Models/CNN_model_V1.keras")
            st.sidebar.success("âœ“ CNN Model Loaded")
        except Exception as e:
            st.sidebar.error(f"âœ— CNN Model: {str(e)[:50]}...")
        
        # Load EfficientNetB0 Model
        try:
            models["EfficientNetB0 (128x128)"] = tf.keras.models.load_model("Models/EfficientNetB0_model.h5")
            st.sidebar.success("âœ“ EfficientNetB0 Model Loaded")
        except Exception as e:
            st.sidebar.error(f"âœ— EfficientNetB0: {str(e)[:50]}...")
        
        # Load EfficientNetB0_V2 Model
        try:
            models["EfficientNetB0_V2 (128x128)"] = tf.keras.models.load_model(
                "Models/EfficientV2.keras",
                custom_objects={"preprocess_input": custom_preprocess_input}
            )
            st.sidebar.success("âœ“ EfficientNetB0_V2 Model Loaded")
        except Exception as e:
            st.sidebar.error(f"âœ— EfficientNetB0_V2: {str(e)[:50]}...")
        
        # Load ResNet50 Model
        try:
            models["ResNet50 (224x224)"] = tf.keras.models.load_model("Models/ResNet50_model_updated.keras")
            st.sidebar.success("âœ“ ResNet50 Model Loaded")
        except Exception as e:
            st.sidebar.error(f"âœ— ResNet50: {str(e)[:50]}...")
        
        return models
    except Exception as e:
        st.error(f"Error loading models: {str(e)}")
        return {}

models = load_models()

# ===========================
# Class Names
# ===========================
class_names = [
    'A','B','C','D','E','F','G','H','I','J','K','L','M',
    'N','O','P','Q','R','S','T','U','V','W','X','Y','Z',
    'del', 'nothing', 'space'  
]

# ===========================
# Webcam Functions with LIVE PREVIEW
# ===========================
def capture_with_preview():
    """Capture photo from webcam with live preview in Streamlit"""
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        st.error("âŒ Cannot access webcam. Please check camera permissions.")
        return None
    
    # Set camera properties
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    st.session_state.camera_active = True
    st.session_state.show_preview = True
    
    # Create placeholders
    preview_placeholder = st.empty()
    status_placeholder = st.empty()
    button_placeholder = st.empty()
    
    captured_image = None
    
    # Buttons
    col1, col2 = button_placeholder.columns(2)
    
    with col1:
        capture_btn = st.button("ğŸ“¸ CAPTURE NOW", key="live_capture", type="primary", use_container_width=True)
    
    with col2:
        cancel_btn = st.button("âŒ CANCEL", key="cancel_capture", use_container_width=True)
    
    # Capture loop
    while st.session_state.camera_active:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Create display frame with annotations
        display_frame = frame.copy()
        height, width = display_frame.shape[:2]
        
        # Draw green box for hand placement
        box_size = 300
        x1 = width // 2 - box_size // 2
        y1 = height // 2 - box_size // 2
        x2 = x1 + box_size
        y2 = y1 + box_size
        
        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
        
        # Add instruction text
        cv2.putText(display_frame, "Place hand in green box", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        cv2.putText(display_frame, "Press 'CAPTURE NOW' button", (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # Convert BGR to RGB for Streamlit
        display_frame_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
        
        # Show live preview
        preview_placeholder.image(display_frame_rgb, channels="RGB", 
                                 caption="Live Camera Preview - Place hand in green box",
                                 use_container_width=True)
        
        # Show status
        status_placeholder.info("ğŸŸ¢ Camera is active - Adjust your hand position")
        
        # Check for button presses
        if capture_btn:
            # Crop to green box area
            if y1 >= 0 and x1 >= 0 and y2 <= height and x2 <= width:
                captured_frame = frame[y1:y2, x1:x2]
            else:
                captured_frame = frame
            
            # Convert to RGB
            captured_image = cv2.cvtColor(captured_frame, cv2.COLOR_BGR2RGB)
            
            # Save to session state
            st.session_state.captured_image = Image.fromarray(captured_image)
            st.session_state.camera_active = False
            
            # Show success message
            status_placeholder.success("âœ… Photo captured successfully!")
            
            # Show captured image
            st.image(captured_image, caption="Captured Hand Sign", use_container_width=True)
            break
        
        elif cancel_btn:
            status_placeholder.warning("âŒ Camera closed")
            st.session_state.camera_active = False
            break
        
        # Small delay to prevent high CPU usage
        time.sleep(0.03)
    
    # Cleanup
    cap.release()
    cv2.destroyAllWindows()
    st.session_state.camera_active = False
    st.session_state.show_preview = False
    
    return captured_image

# ===========================
# Preprocessing Function (Updated to return only processed img for prediction)
# ===========================
def prepare_image(image, model_name):
    """Prepare image for model prediction"""
    if isinstance(image, np.ndarray):
        image = Image.fromarray(image)
    
    if model_name == "CNN (128x128)":
        target_size = (128, 128)
        img = image.resize(target_size)
        img_array = np.array(img).astype(np.float32) 
        return img_array.reshape(1, 128, 128, 3), np.array(img)  # return orig for display
    
    elif model_name == "EfficientNetB0 (128x128)":
        target_size = (128, 128)
        img = image.resize(target_size)
        img_array = np.array(img).astype(np.float32)
        img_array = efficient_preprocess(img_array)
        return img_array.reshape(1, 128, 128, 3), np.array(img)
    
    elif model_name == "EfficientNetB0_V2 (128x128)":
        target_size = (128, 128)
        img = image.resize(target_size)
        img_array = np.array(img).astype(np.float32)
        img_array = efficient_preprocess(img_array)
        return img_array.reshape(1, 128, 128, 3), np.array(img)
    
    elif model_name == "ResNet50 (224x224)":
        target_size = (224, 224)
        img = image.resize(target_size)
        img_array = np.array(img).astype(np.float32)
        img_array = resnet_preprocess(img_array)
        return img_array.reshape(1, 224, 224, 3), np.array(img)
    
    else:
        target_size = (128, 128)
        img = image.resize(target_size)
        img_array = np.array(img).astype(np.float32) / 255.0
        return img_array.reshape(1, 128, 128, 3), np.array(img)



def find_last_conv_layer(model):
    for layer in reversed(model.layers):
        # Case 1: direct Conv2D layer
        if isinstance(layer, tf.keras.layers.Conv2D):
            return layer.name

        # Case 2: Nested model (EfficientNet inside Sequential)
        if isinstance(layer, tf.keras.Model):
            for sub_layer in reversed(layer.layers):
                if isinstance(sub_layer, tf.keras.layers.Conv2D):
                    return sub_layer.name

    raise ValueError("No convolutional layer found in the model.")




def get_last_conv_layer(model):
    for layer in reversed(model.layers):
        if isinstance(layer, tf.keras.Model):
            for sub_layer in reversed(layer.layers):
                if isinstance(sub_layer, tf.keras.layers.Conv2D):
                    return sub_layer
        if isinstance(layer, tf.keras.layers.Conv2D):
            return layer
    raise ValueError("No Conv2D layer found.")




def make_gradcam_heatmap(img_array, model):
    last_conv_layer = get_last_conv_layer(model)

    grad_model = tf.keras.models.Model(
        inputs=model.inputs,
        outputs=[last_conv_layer.output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)

        if isinstance(predictions, (list, tuple)):
            predictions = predictions[0]

        pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    # gradients
    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)

    heatmap = tf.maximum(heatmap, 0)
    heatmap /= tf.reduce_max(heatmap) + 1e-10

    return heatmap.numpy()




# ===========================
# Streamlit UI - Main Page
# ===========================
st.markdown('<h1 class="main-header">âœ‹ ASL Alphabet Recognition System</h1>', unsafe_allow_html=True)

# Sidebar navigation
st.sidebar.markdown("## Navigation")
page = st.sidebar.radio(
    "Go to:",
    ["ğŸ  Single Model", "ğŸ“Š Model Comparison", "ğŸ“ˆ Model Performance"]
)

# Input method in sidebar
st.sidebar.markdown("---")
st.sidebar.markdown("## ğŸ“· Input Options")
input_method = st.sidebar.radio(
    "Choose input method:",
    ["ğŸ“ Upload Image", "ğŸ“¸ Live Webcam"]
)

# Clear button
if st.sidebar.button("ğŸ—‘ï¸ Clear All", type="secondary"):
    st.session_state.captured_image = None
    st.session_state.camera_active = False
    st.session_state.prediction_made = False
    st.session_state.prediction_results = None
    st.rerun()

# Model info in sidebar
st.sidebar.markdown("---")
st.sidebar.markdown("## ğŸ¤– Available Models")
for model_name in models.keys():
    st.sidebar.markdown(f"- {model_name}")

# ===========================
# Page 1: Single Model Prediction 
# ===========================
if page == "ğŸ  Single Model":
    st.markdown('<h2 class="sub-header">Single Model Prediction</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### ğŸ“¸ Input Image")
        
        image = None
        
        if input_method == "ğŸ“ Upload Image":
            uploaded_file = st.file_uploader(
                "Choose an ASL hand sign image",
                type=["jpg", "jpeg", "png"],
                help="Upload an image of ASL alphabet sign",
                key="file_uploader"
            )
            
            if uploaded_file is not None:
                try:
                    image = Image.open(uploaded_file).convert("RGB")
                    st.image(image, caption="Uploaded Image", use_container_width=True)
                except Exception as e:
                    st.error(f"Error loading image: {str(e)}")
        
        elif input_method == "ğŸ“¸ Live Webcam":
            st.markdown("### Live Webcam Capture")
            
            if not st.session_state.camera_active and not st.session_state.captured_image:
                st.info("ğŸ‘† Click 'Start Live Preview' to see camera feed")
                
                if st.button("ğŸ¥ Start Live Preview", type="primary", use_container_width=True):
                    st.session_state.camera_active = True
                    st.rerun()
            
            elif st.session_state.camera_active:
                st.markdown('<div class="camera-preview">', unsafe_allow_html=True)
                st.markdown("#### ğŸ”´ LIVE PREVIEW")
                capture_with_preview()
                st.markdown('</div>', unsafe_allow_html=True)



            
            if st.session_state.captured_image is not None:
                st.markdown('<div class="captured-image-box">', unsafe_allow_html=True)
                st.markdown("#### âœ… CAPTURED IMAGE")
                st.image(st.session_state.captured_image, 
                        caption="Your Hand Sign (Cropped from green box)", 
                        use_container_width=True)
                
                col_act1, col_act2, col_act3 = st.columns(3)
                with col_act1:
                    if st.button("âœ… Use This", type="primary", use_container_width=True):
                        image = st.session_state.captured_image
                        st.success("âœ… Image selected for prediction")
                
                with col_act2:
                    if st.button("ğŸ”„ Retake", use_container_width=True):
                        st.session_state.captured_image = None
                        st.session_state.camera_active = True
                        st.rerun()
                
                with col_act3:
                    if st.button("ğŸ—‘ï¸ Discard", use_container_width=True):
                        st.session_state.captured_image = None
                        st.rerun()
                
                st.markdown('</div>', unsafe_allow_html=True)

                
                image = st.session_state.captured_image
        
        if image is None:
            with st.expander("ğŸ“š Quick ASL Reference"):
                st.markdown("""
                **Common Letters:**
                - **A**: âœŠ Fist with thumb alongside
                - **B**: âœ‹ Flat palm, fingers together  
                - **C**: C Curved fingers
                - **D**: ğŸ‘† Index finger up
                - **L**: ğŸ‘Œ OK sign
                - **Y**: ğŸ¤˜ Rock on sign
                """)
    
    with col2:
        st.markdown("### ğŸ¤– Model Selection & Prediction")
        
        if not models:
            st.error("âŒ No models loaded. Please check model files.")
        else:
            model_choice = st.selectbox(
                "Select a model:",
                list(models.keys()),
                key="model_select"
            )
            
            current_image = None
            if input_method == "ğŸ“ Upload Image" and image is not None:
                current_image = image
            elif input_method == "ğŸ“¸ Live Webcam" and st.session_state.captured_image is not None:
                current_image = st.session_state.captured_image
            
            if current_image is not None:
                st.markdown("---")
                st.markdown("### ğŸš€ Ready to Predict!")
                st.image(current_image, width=250, caption="Image for Prediction")
                
                if st.button("ğŸ¯ PREDICT NOW", type="primary", use_container_width=True):
                    with st.spinner("ğŸ” Analyzing hand sign..."):
                        try:
                            # Prepare image
                            img_ready, img_display = prepare_image(current_image, model_choice)
                            
                            # Get model and predict â€” Ø¨Ø¯ÙˆÙ† normalize
                            model = models[model_choice]
                            prediction = model.predict(img_ready, verbose=0)  # shape: (1, 29)
                            
                            # ğŸ”¹ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù‡Ù†Ø§: Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
                            predicted_index = np.argmax(prediction)
                            predicted_letter = class_names[predicted_index]
                            confidence = float(np.max(prediction)) * 100  # âœ… Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨

                            # Top 3 using raw prediction (assuming softmax output)
                            top_3_idx = np.argsort(prediction[0])[-3:][::-1]
                            top_3_classes = [class_names[i] for i in top_3_idx]
                            top_3_confidences = [float(prediction[0][i]) * 100 for i in top_3_idx]

                            # Store results
                            st.session_state.prediction_results = {
                                'predicted_letter': predicted_letter,
                                'confidence': confidence,
                                'top_3_classes': top_3_classes,
                                'top_3_confidences': top_3_confidences,
                                'model_name': model_choice,
                                'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
                            }
                            st.session_state.prediction_made = True
                            
                            # Display results
                            st.markdown('<div class="prediction-box">', unsafe_allow_html=True)
                            st.markdown("## ğŸ“Š Prediction Results")
                            st.markdown(f"### ğŸ¯ **{predicted_letter}**")
                            
                            if confidence > 85:
                                emoji = "ğŸŸ¢"
                                color = "#4CAF50"
                            elif confidence > 70:
                                emoji = "ğŸŸ¡"
                                color = "#FF9800"
                            else:
                                emoji = "ğŸ”´"
                                color = "#F44336"
                            
                            st.markdown(f"**Confidence:** {emoji} <span style='color:{color}; font-size:24px; font-weight:bold;'>{confidence:.2f}%</span>", 
                                       unsafe_allow_html=True)
                            
                            st.progress(min(int(confidence), 100), text=f"{confidence:.2f}% confidence")
                            
                            st.markdown("#### Other Predictions:")
                            for i in range(1, 3):
                                col_a, col_b = st.columns([1, 3])
                                with col_a:
                                    st.markdown(f"**{i+1}. {top_3_classes[i]}**")
                                with col_b:
                                    conf = min(max(top_3_confidences[i], 0), 100)
                                    st.progress(int(conf), text=f"{top_3_confidences[i]:.2f}%")
                            
                            st.markdown('</div>', unsafe_allow_html=True)


                            st.markdown("### ğŸ”¥ Grad-CAM Explanation")

                            heatmap = make_gradcam_heatmap(img_ready, model)

                            img = np.array(current_image)
                            heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
                            heatmap = np.uint8(255 * heatmap)

                            heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
                            superimposed_img = cv2.addWeighted(img, 0.7, heatmap, 0.3, 0)

                            st.image(superimposed_img, caption="Grad-CAM Heatmap", use_container_width=True)



##########################################################################
                            # Visualization: Top 10
                            st.markdown("### ğŸ“ˆ Top 10 Predictions")
                            
                            top_10_idx = np.argsort(prediction[0])[::-1][:10]
                            top_10_classes = [class_names[i] for i in top_10_idx]
                            top_10_confidences = [float(prediction[0][i]) * 100 for i in top_10_idx]
                            
                            fig, ax = plt.subplots(figsize=(10, 6))
                            colors = plt.cm.YlOrRd(np.linspace(0.4, 0.9, len(top_10_classes)))
                            bars = ax.barh(top_10_classes[::-1], top_10_confidences[::-1], color=colors)
                            
                            ax.set_xlabel('Confidence (%)')
                            ax.set_title(f'Top 10 Predictions - {model_choice}')
                            ax.set_xlim(0, 100)
                            
                            for bar, conf in zip(bars, top_10_confidences[::-1]):
                                width = bar.get_width()
                                ax.text(width + 1, bar.get_y() + bar.get_height()/2, 
                                       f'{conf:.1f}%', va='center', fontweight='bold')
                            
                            st.pyplot(fig)
                            
                            with st.expander("ğŸ” View Detailed Analysis"):
                                st.write(f"**Model:** {model_choice}")
                                st.write(f"**Time:** {time.strftime('%H:%M:%S')}")
                                
                                st.markdown("**All Predictions (Top 15):**")
                                all_preds = []
                                for i in range(len(class_names)):
                                    all_preds.append({
                                        "Class": class_names[i],
                                        "Confidence": f"{prediction[0][i] * 100:.2f}%"
                                    })
                                
                                all_preds.sort(key=lambda x: float(x['Confidence'].strip('%')), reverse=True)
                                
                                for i, pred in enumerate(all_preds[:15]):
                                    if i < 3:
                                        medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i]
                                        st.write(f"{medal} **{pred['Class']}**: {pred['Confidence']}")
                                    else:
                                        st.write(f"{i+1}. {pred['Class']}: {pred['Confidence']}")
                        
                        except Exception as e:
                            st.error(f"âŒ Prediction error: {str(e)}")
            
            elif st.session_state.prediction_made and st.session_state.prediction_results:
                results = st.session_state.prediction_results
                
                st.markdown("## ğŸ“‹ Previous Prediction")
                st.markdown(f"### Result: **{results['predicted_letter']}**")
                st.markdown(f"#### Confidence: **{results['confidence']:.2f}%**")
                st.markdown(f"*Model: {results['model_name']} | Time: {results['timestamp']}*")
                
                if st.button("ğŸ”„ Make New Prediction", type="secondary"):
                    st.session_state.prediction_made = False
                    st.session_state.prediction_results = None
                    st.rerun()
            
            else:
                st.info("ğŸ‘† Capture or upload an image first, then click 'PREDICT NOW'")

# ===========================
# Page 2: Model Comparison (Updated to use raw prediction)
# ===========================
elif page == "ğŸ“Š Model Comparison":
    st.markdown('<h2 class="sub-header">Model Comparison</h2>', unsafe_allow_html=True)
    
    st.info("ğŸ” Compare predictions across all models")
    
    comparison_image = None
    
    if input_method == "ğŸ“ Upload Image":
        uploaded_file = st.file_uploader(
            "Upload image for comparison",
            type=["jpg", "jpeg", "png"],
            key="compare_upload"
        )
        if uploaded_file is not None:
            comparison_image = Image.open(uploaded_file).convert("RGB")
    
    elif input_method == "ğŸ“¸ Live Webcam":
        if st.session_state.captured_image is not None:
            comparison_image = st.session_state.captured_image
            st.image(comparison_image, caption="Captured Image", use_container_width=True)
        else:
            st.info("No captured image. Go to 'Single Model' page to capture first.")
    
    if comparison_image is not None and st.button("ğŸ”„ Compare All Models", type="primary", use_container_width=True):
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for idx, (model_name, model) in enumerate(models.items()):
            status_text.text(f"Processing {model_name}...")
            progress_bar.progress((idx + 1) / len(models))
            
            try:
                img_ready, _ = prepare_image(comparison_image, model_name)
                prediction = model.predict(img_ready, verbose=0)
                
                pred_idx = np.argmax(prediction)
                pred_class = class_names[pred_idx]
                confidence = float(np.max(prediction)) * 100
                
                results.append({
                    "Model": model_name,
                    "Prediction": pred_class,
                    "Confidence": f"{confidence:.2f}%",
                    "Raw Confidence": confidence
                })
                
            except Exception as e:
                st.error(f"Error with {model_name}: {str(e)}")
        
        status_text.text("âœ… Comparison complete!")
        progress_bar.empty()
        
        st.markdown("### ğŸ“‹ Comparison Results")
        results.sort(key=lambda x: x["Raw Confidence"], reverse=True)
        
        for i, result in enumerate(results):
            with st.container():
                cols = st.columns([1, 3, 2, 2])
                
                with cols[0]:
                    rank_emoji = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"][i] if i < 5 else f"{i+1}."
                    st.markdown(f"**{rank_emoji}**")
                
                with cols[1]:
                    st.markdown(f"**{result['Model']}**")
                
                with cols[2]:
                    st.markdown(f"**{result['Prediction']}**")
                
                with cols[3]:
                    conf_color = "#4CAF50" if result["Raw Confidence"] > 80 else "#FF9800" if result["Raw Confidence"] > 60 else "#F44336"
                    st.markdown(f"<span style='color:{conf_color}; font-weight:bold;'>{result['Confidence']}</span>", 
                               unsafe_allow_html=True)
                
                st.progress(min(int(result["Raw Confidence"]), 100))

# ===========================
# Page 3: Model Performance
# ===========================
elif page == "ğŸ“ˆ Model Performance":
    st.markdown('<h2 class="sub-header">Model Performance Metrics</h2>', unsafe_allow_html=True)
    
    col_select, col_info = st.columns([2, 1])
    
    with col_select:
        selected_model = st.selectbox(
            "Select model to view performance:",
            list(models.keys()),
            key="perf_select"
        )
    
    with col_info:
        if selected_model:
            accuracy = 0.90
            st.metric("Model Accuracy", f"{accuracy*100:.1f}%")
    
    if selected_model:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Classes", "29")
        with col2:
            input_size = "128Ã—128" if "128" in selected_model else "224Ã—224"
            st.metric("Input Size", input_size)
        with col3:
            st.metric("Model Type", selected_model.split()[0])

# ===========================
# Footer
# ===========================
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    <h4>âœ‹ ASL Alphabet Recognition System</h4>
    <p><strong>Live Webcam Preview â€¢ Instant Prediction â€¢ Multi-Model Comparison</strong></p>
    <p>See camera feed directly in browser â€¢ Green box for hand placement</p>
</div>
""", unsafe_allow_html=True)