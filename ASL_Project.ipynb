{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1arqjIJj_sBkcI3n-fOMIA5Xv-aik2pcY",
      "authorship_tag": "ABX9TyMs5D/1fb5ttv9kY6RW0XuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeyad-mohvme-d/-Sign-Language-Fingerspelling-Assistant-ASL-Alphabet-/blob/main/ASL_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import os"
      ],
      "metadata": {
        "id": "_dK5bVI58FDz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcrLRxwy_SZ-",
        "outputId": "15f47523-f706-4f3a-93a4-74853ade78fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'asl-alphabet' dataset.\n",
            "Path to dataset files: /kaggle/input/asl-alphabet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/kaggle/input/asl-alphabet\"\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    os.path.join(path, \"asl_alphabet_train/asl_alphabet_train\"),\n",
        "    validation_split = 0.1,\n",
        "    subset = \"training\",\n",
        "    seed = 123,\n",
        "    image_size = (128, 128),\n",
        "    batch_size = 32\n",
        ")\n",
        "\n",
        "\n",
        "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    os.path.join(path, \"asl_alphabet_train\", \"asl_alphabet_train\"),\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(64, 64),\n",
        "    batch_size=32\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHdrxrrbhjt8",
        "outputId": "750eef19-2e63-4219-8f99-675da96c63b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87000 files belonging to 29 classes.\n",
            "Using 78300 files for training.\n",
            "Found 87000 files belonging to 29 classes.\n",
            "Using 8700 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "BOgykjf3i-1e",
        "outputId": "317bef38-2477-4208-b5ec-5f28b4d84a4c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.prefetch_op._PrefetchDataset</b><br/>def __init__(input_dataset, buffer_size, slack_period=None, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/prefetch_op.py</a>A `Dataset` that asynchronously prefetches its input.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 31);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enyrif68jvBG",
        "outputId": "1819ac47-3f04-4094-f780-44431380170d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2447"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clas_names = train_data.class_names\n",
        "clas_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrXz-X2pjxhE",
        "outputId": "74ca1e18-514c-4883-f896-aa42b9312a75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'del',\n",
              " 'nothing',\n",
              " 'space']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = {}\n",
        "\n",
        "for i in range(26):\n",
        "    m[chr(ord('A') + i)] = i\n",
        "\n",
        "m[\"nothing\"] = 27\n",
        "m[\"space\"] = 28"
      ],
      "metadata": {
        "id": "3lCxxd__ksXh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "test_labels = []\n",
        "\n",
        "test_path = os.path.join(path, \"asl_alphabet_test\", \"asl_alphabet_test\")\n",
        "image_size = (128, 128)\n",
        "\n",
        "\n",
        "for filename in os.listdir(test_path):\n",
        "  img_path = os.path.join(test_path, filename)\n",
        "  char = filename.split(\"_\")[0]\n",
        "  test_labels.append(m[char])\n",
        "  img = load_img(img_path, target_size=image_size)\n",
        "  img_array = img_to_array(img)\n",
        "  test_data.append(img_array)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(test_data[0].shape)\n",
        "print(test_labels)\n",
        "\n",
        "\n",
        "test_data = np.array(test_data)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flD1dH4LloXg",
        "outputId": "4fbb9ae8-41a8-4fe8-c27e-103a83ba6584"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128, 3)\n",
            "[0, 4, 11, 13, 18, 3, 6, 8, 22, 12, 27, 23, 7, 16, 2, 19, 15, 21, 24, 20, 28, 14, 1, 17, 5, 25, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DLgxseGjmYyr"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}